{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Changing_Room_Coding_Challenge.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Problem Statement :\n",
        "\n",
        "Write an application to crawl an online fashion brand website, e.g. https://www.fordays.com, https://www.reformation.com or https://www.zara.com using a crawler framework such as Selenium, bs4, etc. You can use a crawl framework of your choice in Python. (YOU ONLY NEED TO SCRAPE A FEW PRODUCTS, not entire website, however, please explain your strategy to scrape the whole website, extract all the URLs and update the database automatically overtime (new products, update old products not available anymore)\n",
        "\n",
        "this is an example of how the extracted information should be structured:\n",
        "\n",
        "1.   display_name (str)\n",
        "2.   product_material (str)\n",
        "1.   color (str)\n",
        "1.   size (list)\n",
        "1.   price (str)\n",
        "6.   product_url (str)\n",
        "7.   image_links (list)\n",
        "8.   brand_name (str)\n",
        "1.   description (str)\n",
        "2.   scrapped_date (date)\n",
        "1.   low_level (str) [category of clothes: e.g. casual pants, dress]\n",
        "2.   gender (str) [men, women, or kids]\n",
        "13.  secondhand (bool) [is it from a second hand retailer, already worn?]\n",
        "\n",
        "Store the data in a hosted PostGRES database."
      ],
      "metadata": {
        "id": "kTHpyxgrZehI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jEoENM5ZFJ1",
        "outputId": "ce58cd0d-f217-4eb7-a71a-86a7ea56a0ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (4.6.3)\n"
          ]
        }
      ],
      "source": [
        "#! pip install beautifulsoup4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import psycopg2\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.request import urlopen,Request\n",
        "\n",
        "import sys\n",
        "!{sys.executable} -m pip install psycopg2\n",
        "\n",
        "\n",
        "# os.environ['host'] = /// set as your RDS endpoint \n",
        "# os.environ['username'] = /// set as your username\n",
        "# os.environ['password'] = /// Set as your password\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m83xViuFcMCA",
        "outputId": "72aa9e21-42a0-43c9-8302-e829d70473a5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
            "  \"\"\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: psycopg2 in /usr/local/lib/python3.7/dist-packages (2.7.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_product_details(url):\n",
        "  # Empty dictionary to store the results\n",
        "  product = {}\n",
        "\n",
        "  # Getting the HTML Data from the specified url\n",
        "  req = Request(url)\n",
        "  page = urlopen(req)\n",
        "  html = page.read().decode(\"utf-8\")\n",
        "  soup = BeautifulSoup(html, \"html.parser\")\n",
        "  text = soup.get_text()\n",
        "\n",
        "  # Extracting the display name of the product\n",
        "  main_body = soup.find('div',{'class':'pdp-main__details max-width--xmedium'})\n",
        "  title = main_body.find('div',{'class':'pdp__title'})\n",
        "  display_name = str(title.h1.contents[0]).replace('\\n','')\n",
        "\n",
        "  #Extracting the price details of the product\n",
        "  price_details = main_body.find('div',{'class':'price'}).find('span',{'class':'price--reduced'}).string\n",
        "  price_details = price_details.replace('\\n','')\n",
        "\n",
        "  #Extracting the description of the product \n",
        "  main_details = main_body.find('div',{'class':'pdp__description display--small-up font-size--14 font-family--book margin-b--15'}).find('div',{'class':'cms-generic-copy'})\n",
        "  description = str(main_details.string).replace('\\n','')\n",
        "\n",
        "  #Extracting the color of the product\n",
        "  attributes = main_body.find('div',{'class':'product-attribute__list'})\n",
        "  color_attr = attributes.find('label',{'class':'product-attribute__label product-attribute__label--color form-control-label'})\n",
        "  color = str(color_attr.find('span',{'class':'product-attribute__selected-value'}).contents)\n",
        "\n",
        "  #Extracting the size of the product \n",
        "  size_attr = attributes.find('div',{'class':'product-attribute product-attribute--size product-attribute--type-anchor product-attribute--last'})\n",
        "  size_attr = size_attr.find('div',{'class':'product-attribute__contents flex flex-flow-wrap'})\n",
        "  #Storing the sizes as a list\n",
        "  sizes = []\n",
        "  for child in size_attr.children:\n",
        "    sizes.append(child.string.replace('\\n',''))\n",
        "  sizes = [sizes[i] for i in range(len(sizes)) if i % 2 == 1]\n",
        "\n",
        "  #Extracting the fabric and details of the product\n",
        "  product_details = main_body.find('div',{'class':'pdp__accordion'})\n",
        "  fabric_care = product_details.find('div',{'class':'pdp__accordion-content js-pdp-care'})\n",
        "  #Extracting only the fabric description which consists of a blend of different fabrics\n",
        "  for info in fabric_care.contents:\n",
        "    if any(chr.isdigit() for chr in info.string):\n",
        "      product_material = info.string\n",
        "\n",
        "\n",
        "\n",
        "  product_material = product_material.replace('\\n','')\n",
        "\n",
        "\n",
        "  product_page = soup.find('div',{'class':'pdp-main'})\n",
        "  bread_crumbs = product_page.find('div',{'class':'pdp__breadcrumbs max-width--xlarge display--medium-up'})\n",
        "  url_pieces = [value \n",
        "            for element in bread_crumbs.find_all('a',class_=True) \n",
        "            for value in element[\"href\"]]\n",
        "  product_url = \"\".join(url_pieces)\n",
        "  product['display_name'] = display_name\n",
        "  product['price_details'] = int(price_details.replace('$',''))\n",
        "  product['description'] = description.replace(\",\",\" \")\n",
        "  product['color'] = color \n",
        "  product['sizes'] = \"[\"+\" \".join(sizes)+\"]\"\n",
        "  product['product_material'] = product_material.replace(\",\",\" \")\n",
        "  product['product_url'] = product_url \n",
        "\n",
        "  return product\n",
        "\n",
        "\n",
        "\n",
        "data = get_product_details(\"https://www.thereformation.com/products/ezrana-knit-tank/1310760BLK.html?dwvar_1310760BLK_color=BLK\")\n"
      ],
      "metadata": {
        "id": "IgxA40eL69AL"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANcvvL3UBEzj",
        "outputId": "389b7d12-09c0-4c44-edb1-85f31a6c56dd"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'color': \"['Black']\",\n",
              " 'description': 'Your arms want some attention. The Ezrana is a sleeveless  fitted top with a square neckline. It features chain link straps and can be worn day-to-night if you ask us.',\n",
              " 'display_name': 'Ezrana Knit Tank',\n",
              " 'price_details': 128,\n",
              " 'product_material': 'Eco Rib is a medium weight  stretchy ribbed knit with a soft handfeel - 88% TENCELâ„¢ lyocell  12% spandex.',\n",
              " 'product_url': 'https://www.thereformation.com//tops/products/ezrana-knit-tank/1310760.html',\n",
              " 'sizes': '[XS S M L XL]'}"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame([data])\n",
        "df['color'] = df['color'].astype(str)\n",
        "df['description'] = df['description'].astype(str)\n",
        "df['display_name'] = df['display_name'].astype(str)\n",
        "df['price_details'] =  df['price_details'].astype(float)\n",
        "df['product_material'] = df['product_material'].astype(str)\n",
        "df['product_url'] = df['product_url'].astype(str)\n",
        "df['sizes'] = df['sizes'].astype(str)"
      ],
      "metadata": {
        "id": "yaBa5q69AiBt"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('new_data.csv',index= None)"
      ],
      "metadata": {
        "id": "mJ5u0pA4GHiD"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!curl ifconfig.me"
      ],
      "metadata": {
        "id": "ZkCayIisAL47"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "connection = psycopg2.connect(\n",
        "    host = os.environ.get('host'),\n",
        "    port = 5432,\n",
        "    user =  os.environ.get('username'),\n",
        "    password =  os.environ.get('password'),\n",
        "    database='postgres'\n",
        "    )\n",
        "cursor=connection.cursor()"
      ],
      "metadata": {
        "id": "iC8ergX0yl78"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cursor.execute(\"\"\"CREATE TABLE product_details_12(\n",
        "display_name text,\n",
        "price_details float,\n",
        "description text,\n",
        "color text,\n",
        "sizes text,\n",
        "product_material text,\n",
        "product_url text)\"\"\")"
      ],
      "metadata": {
        "id": "cUJhBGXFAk0B"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "connection.commit()"
      ],
      "metadata": {
        "id": "eWudxP0__ygK"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('new_data.csv', 'r') as row:\n",
        "    next(row) \n",
        "    cursor.copy_from(row, 'product_details_12', sep=',')"
      ],
      "metadata": {
        "id": "yzG3oveSBzy0"
      },
      "execution_count": 150,
      "outputs": []
    }
  ]
}